# Feature Specification: Twitter/X Feed Integration with Narrative Correlation Engine

**Generated**: 2026-01-09T17:10:49.241426
**Status**: Draft
**Source**: Auto-generated by Smactorio workflow

---

## Overview

Integrate Twitter/X social media feeds into the SIGINT dashboard using a hybrid monitoring approach that combines curated list-based baseline monitoring with event-driven search capabilities. The system includes a deep narrative correlation engine that detects leading indicators and amplification patterns by matching tweet velocity and hashtag spikes with news headlines.

## Problem Statement

The SIGINT dashboard currently lacks real-time social media intelligence from Twitter/X, missing critical early warning signals and narrative amplification patterns in the AI/ML space. Analysts need visibility into how social media narratives correlate with and potentially precede news coverage to identify emerging trends and coordinated messaging campaigns.

---

## User Stories

### US1 - Curated List Baseline Monitoring (Priority: P0)

As a **SIGINT Analyst**, I want to **monitor tweets from a curated list of key AI/ML accounts (e.g., @AnthropicAI, @OpenAI, @ylecun)**, so that **I can track authoritative voices in the AI/ML space and establish baseline narrative patterns**.

**Independent Test**: Configure a test list with 3 accounts, trigger a fetch cycle, and verify tweets are stored in S3 cache and retrievable via API

**Acceptance Criteria**:

1. System maintains a configurable list of Twitter accounts to monitor
2. Tweets from listed accounts are fetched and stored within API rate limits
3. TweetItem model captures tweet content, author, timestamp, engagement metrics, and hashtags
4. Dashboard displays recent tweets from monitored accounts

### US2 - Event-Driven Search on Narrative Spikes (Priority: P0)

As a **SIGINT Analyst**, I want to **trigger targeted Twitter searches when narrative spikes are detected in the existing system**, so that **I can gather additional social media context during emerging events without exhausting API limits**.

**Independent Test**: Simulate a narrative spike event, verify search is triggered, results are cached, and API call count is incremented correctly

**Acceptance Criteria**:

1. System receives spike notifications from existing narrative detection system
2. Targeted search queries are constructed based on spike keywords/topics
3. Search results are fetched only when spikes exceed configurable threshold
4. API calls are budgeted to stay within 1500 reads/month limit

### US3 - Tweet Velocity and Hashtag Spike Detection (Priority: P0)

As a **SIGINT Analyst**, I want to **detect unusual spikes in tweet velocity and hashtag usage**, so that **I can identify emerging narratives and potential coordinated campaigns early**.

**Independent Test**: Inject test tweet data with artificial spike pattern, verify correlation engine detects and reports the spike with correct metrics

**Acceptance Criteria**:

1. Correlation engine calculates tweet velocity over configurable time windows
2. Hashtag frequency is tracked and compared against baseline
3. Spikes are identified when metrics exceed threshold (e.g., 2x baseline)
4. Spike events include timestamp, magnitude, and associated hashtags/keywords

### US4 - News-Tweet Narrative Correlation (Priority: P0)

As a **SIGINT Analyst**, I want to **see correlations between Twitter narrative spikes and news headlines**, so that **I can identify leading indicators where social media precedes news coverage and detect amplification patterns**.

**Independent Test**: Provide matched test data of tweets and news articles on same topic, verify correlation engine produces CorrelatedNarrative with accurate lead time calculation

**Acceptance Criteria**:

1. CorrelatedNarrative model links tweet clusters with news articles
2. Correlation engine matches tweets and news by keywords, entities, and temporal proximity
3. System calculates lead/lag time between social and news narratives
4. Correlation confidence score is provided for each match

### US5 - Aggressive S3 Caching for API Optimization (Priority: P0)

As a **System Administrator**, I want to **ensure Twitter API responses are aggressively cached to S3**, so that **the system respects free tier API limits while maintaining data availability**.

**Independent Test**: Make duplicate requests for same data, verify second request is served from cache with no API call made

**Acceptance Criteria**:

1. All Twitter API responses are cached to S3 with configurable TTL
2. Cache is checked before making any API call
3. Cache hit/miss metrics are logged
4. Monthly API usage is tracked and alerts triggered at 80% threshold

### US6 - Twitter Lambda Handler Implementation (Priority: P1)

As a **Developer**, I want to **deploy Twitter integration as a Lambda function with proper event handling**, so that **the system can process Twitter data in a serverless, scalable manner**.

**Independent Test**: Invoke Lambda with test event payloads for both scheduled and spike-triggered scenarios, verify correct execution paths and outputs

**Acceptance Criteria**:

1. Lambda handler processes scheduled fetch events for list monitoring
2. Lambda handler processes spike notification events for targeted search
3. Handler includes proper error handling and retry logic
4. CloudWatch logs capture execution details and errors

### US7 - Twitter Client Module (Priority: P1)

As a **Developer**, I want to **use a well-structured twitter_client.py module for all Twitter API interactions**, so that **I can easily maintain and extend Twitter integration functionality**.

**Independent Test**: Unit test twitter_client.py methods with mocked API responses, verify correct parsing and caching behavior

**Acceptance Criteria**:

1. twitter_client.py provides methods for list timeline fetch and search
2. Client handles authentication and rate limit headers
3. Client integrates with S3 caching layer
4. Client raises appropriate exceptions for API errors

### US8 - AI/ML Category Pilot Configuration (Priority: P1)

As a **SIGINT Analyst**, I want to **have the Twitter integration pre-configured for AI/ML category monitoring**, so that **I can immediately start gathering intelligence on the AI/ML narrative landscape**.

**Independent Test**: Deploy with default configuration, verify AI/ML accounts are monitored and relevant hashtags tracked

**Acceptance Criteria**:

1. Default configuration includes key AI/ML accounts (@AnthropicAI, @OpenAI, @ylecun, etc.)
2. AI/ML relevant hashtags are pre-configured for spike detection
3. Category can be easily extended or modified via configuration

### US9 - Integration with Existing Narrative Detection (Priority: P1)

As a **Developer**, I want to **integrate Twitter correlation data with the existing narrative detection system**, so that **analysts have a unified view of narratives across news and social media**.

**Independent Test**: Create correlated narrative with Twitter data, verify it appears correctly in existing dashboard and API responses

**Acceptance Criteria**:

1. Twitter narratives appear in existing narrative dashboard
2. Correlated narratives show both news and tweet sources
3. Existing narrative APIs accept and return Twitter-sourced data
4. No breaking changes to existing narrative system interfaces

---

## Entities

### TweetItem
**Type**: entity
**Description**: Represents a single tweet from Twitter/X
**Attributes**:
  - tweet_id
  - author_handle
  - author_id
  - content
  - created_at
  - hashtags
  - mentions
  - retweet_count
  - like_count
  - reply_count
  - fetched_at
  - source_type

### CorrelatedNarrative
**Type**: entity
**Description**: Represents a detected correlation between Twitter activity and news coverage
**Attributes**:
  - correlation_id
  - tweet_cluster_ids
  - news_article_ids
  - keywords
  - hashtags
  - tweet_spike_time
  - news_publish_time
  - lead_lag_hours
  - confidence_score
  - amplification_factor
  - detected_at

## Functional Requirements

FR-001: FR-001: System shall fetch tweets from a configurable list of Twitter accounts on a scheduled basis
FR-002: FR-002: System shall perform targeted Twitter searches when narrative spikes exceed threshold
FR-003: FR-003: System shall calculate tweet velocity over configurable time windows (15min, 1hr, 24hr)
FR-004: FR-004: System shall detect hashtag frequency spikes against rolling baseline
FR-005: FR-005: System shall correlate tweet clusters with news articles by keyword and temporal proximity
FR-006: FR-006: System shall calculate lead/lag time between social media and news narratives
FR-007: FR-007: System shall cache all Twitter API responses to S3 with configurable TTL
FR-008: FR-008: System shall track monthly API usage and enforce 1500 read limit
FR-009: FR-009: System shall expose Twitter data through existing narrative detection APIs
FR-010: FR-010: System shall store TweetItem and CorrelatedNarrative models in DynamoDB

## Non-Functional Requirements

NFR-001: NFR-001: API usage must not exceed 1500 reads per month (Twitter free tier limit)
NFR-002: NFR-002: Cache hit rate should exceed 80% for repeated queries
NFR-003: NFR-003: Correlation engine should process tweet batches within 30 seconds
NFR-004: NFR-004: Lambda cold start time should be under 3 seconds
NFR-005: NFR-005: System should handle Twitter API rate limit errors gracefully with exponential backoff
NFR-006: NFR-006: All PII in tweets should be handled according to data retention policies

## Business Rules

- BR-001: Only tweets from public accounts may be collected
- BR-002: Cached tweets must be refreshed at least every 24 hours for monitored accounts
- BR-003: Event-driven searches are only triggered when spike magnitude exceeds 2x baseline
- BR-004: API budget allocation: 70% for list monitoring, 30% for event-driven search
- BR-005: Correlation confidence must exceed 0.6 to be surfaced to analysts
- BR-006: Lead time calculation considers tweets leading news as positive intelligence value

## Assumptions

- Twitter/X API free tier provides sufficient access for list timeline and search endpoints
- Existing narrative detection system has a notification mechanism for spike events
- S3 bucket for caching is already provisioned and accessible
- DynamoDB tables can be extended for new models without migration
- AI/ML category accounts are publicly accessible and actively posting

## Open Questions

- [ ] What is the exact threshold for narrative spike that should trigger event-driven search?
- [ ] Should deleted tweets be tracked or removed from cache?
- [ ] How should the system handle Twitter API changes or deprecations?
- [ ] What is the retention period for cached tweets and correlation data?
- [ ] Should correlation engine consider sentiment alignment in addition to keyword matching?

## Success Criteria

- Twitter integration successfully monitors at least 10 AI/ML accounts within API limits
- Correlation engine identifies at least 3 validated narrative correlations in first month
- API usage stays below 1500 reads/month with cache hit rate above 80%
- Lead time detection accurately identifies cases where tweets precede news by 2+ hours
- Integration with existing narrative system is seamless with no breaking changes
- All components (twitter_client.py, correlation_engine.py, Lambda handler) pass unit tests
